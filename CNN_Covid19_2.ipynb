{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSEUNrzg-9js"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/my\\content/gdrive/MyDrive/DBSCAN.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQYYVs7WPcWN",
        "outputId": "eeccae54-c763-43c4-af12-ae8b822a7746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open gdrive/mycontent/gdrive/MyDrive/DBSCAN.zip, gdrive/mycontent/gdrive/MyDrive/DBSCAN.zip.zip or gdrive/mycontent/gdrive/MyDrive/DBSCAN.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_path_b = '/content/gdrive/MyDrive/DBSCAN.zip'"
      ],
      "metadata": {
        "id": "RfUchqhzSKot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8WW7b-dipm0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# General libraries\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Deep learning libraries\n",
        "#import keras.backend as K\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "#Util Component 1: Confusion matrix report/Accuracy measures\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# disabling warnings\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True #Jordan_note: Disable red warning lines seen at model architecture creation."
      ],
      "metadata": {
        "id": "qptZuP_YX7c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def renderConfusionMetrics ( ___model, _testData, _testLabels, enableTraining, ___train_gen, ___test_gen, __batch_size, __epochs, hdf5_testSaveFileName ):\n",
        "    preds = ___model.predict(_testData)\n",
        "\n",
        "    acc = accuracy_score(_testLabels, np.round(preds))*100\n",
        "    cm = confusion_matrix(_testLabels, np.round(preds))\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "\n",
        "    print('\\nCONFUSION MATRIX FORMAT ------------------\\n')\n",
        "    print(\"[true positives    false positives]\")\n",
        "    print(\"[false negatives    true negatives]\\n\\n\")\n",
        "\n",
        "    print('CONFUSION MATRIX ------------------')\n",
        "    print(cm)\n",
        "\n",
        "    print('\\nTEST METRICS ----------------------')\n",
        "    precision = tp/(tp+fp)*100\n",
        "    recall = tp/(tp+fn)*100\n",
        "    specificity = tn/(tn+fp)*100 #Jordan_note: added specificity calculation \n",
        "    print('Accuracy: {}%'.format(acc))\n",
        "    print('Precision: {}%'.format(precision))\n",
        "    print('Recall/Sensitivity: {}%'.format(recall)) #Jordan_note: added sensitivity label\n",
        "    print('Specificity {}%'.format(specificity)) #Jordan_note: added specificity calculation \n",
        "    print('F1-score: {}'.format(2*precision*recall/(precision+recall)))\n",
        "\n",
        "\n",
        "    if enableTraining:\n",
        "        checkpoint = ModelCheckpoint(filepath=hdf5_testSaveFileName, save_best_only=True, save_weights_only=True)\n",
        "        lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
        "        early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')\n",
        "\n",
        "\n",
        "        hist = ___model.fit_generator(\n",
        "                   ___train_gen, steps_per_epoch=___test_gen.samples // __batch_size, \n",
        "                   epochs=__epochs, validation_data=___test_gen, \n",
        "                   validation_steps=___test_gen.samples // __batch_size, callbacks=[checkpoint, lr_reduce])\n",
        "\n",
        "        print('\\nTRAIN METRIC ----------------------')\n",
        "        print('Covid19 Train acc: {}'.format(np.round((hist.history['accuracy'][-1])*100, 2)))\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
        "    ax = ax.ravel()\n",
        "    for i, met in enumerate(['accuracy', 'loss']):\n",
        "        ax[i].plot(hist.history[met])\n",
        "        ax[i].plot(hist.history['val_' + met])\n",
        "        ax[i].set_title('Model {}'.format(met))\n",
        "        ax[i].set_xlabel('epochs')\n",
        "        ax[i].set_ylabel(met)\n",
        "        ax[i].legend(['train', 'val'])\n",
        "    plt.savefig('train_val_acc_loss.png')"
      ],
      "metadata": {
        "id": "7olDt8zoX7Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Util Component 2:model architecture description\n",
        "def defineModelArchitecture (_img_dims ):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=(_img_dims, _img_dims, 3))\n",
        "\n",
        "    # First conv block\n",
        "    x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Second conv block\n",
        "    x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Third conv block\n",
        "    x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Fourth conv block\n",
        "    x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "\n",
        "    # Fifth conv block\n",
        "    x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "\n",
        "    # FC layer\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=512, activation='relu')(x)\n",
        "    x = Dropout(rate=0.7)(x)\n",
        "    x = Dense(units=128, activation='relu')(x)\n",
        "    x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(units=64, activation='relu')(x)\n",
        "    x = Dropout(rate=0.3)(x)\n",
        "\n",
        "    # Output layer\n",
        "    output = Dense(units=1, activation='sigmoid')(x)\n",
        "    \n",
        "    return inputs, output\n",
        "\n",
        "\n",
        "###########\n",
        "#Util Component 3: Data processor\n",
        "#Note: This process does not use validation path, because validation path in the original competion reasonably had too little data (8 samples) to create any insight.\n",
        "# the \"directoryProcessArray\" param from \"reportFileDistributions\" function corresponds to the hard-coded sub-directories of train and test, excluding val.\n",
        "def process_data(___inputPath, img_dims, batch_size):\n",
        "    # Data generation objects\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True)\n",
        "    test_val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    # This is fed to the network in the specified batch sizes and image dimensions\n",
        "    train_gen = train_datagen.flow_from_directory(\n",
        "    directory=___inputPath+'train', \n",
        "    target_size=(img_dims, img_dims), \n",
        "    batch_size=batch_size, \n",
        "    class_mode='binary', \n",
        "    shuffle=True)\n",
        "\n",
        "    test_gen = test_val_datagen.flow_from_directory(\n",
        "    directory=___inputPath+'test', \n",
        "    target_size=(img_dims, img_dims), \n",
        "    batch_size=batch_size, \n",
        "    class_mode='binary', \n",
        "    shuffle=True)\n",
        "    \n",
        "    # I will be making predictions off of the test set in one batch size\n",
        "    # This is useful to be able to get the confusion matrix\n",
        "    test_data = []\n",
        "    test_labels = []\n",
        "\n",
        "    for cond in ['/NORMAL/', '/PNEUMONIA/']:\n",
        "        for img in (os.listdir(___inputPath + 'test' + cond)):\n",
        "            img = cv2.imread(___inputPath+'test'+cond+img,0) #Replace plt.imread, with  gray scale cv2.imread(path,0), so that ui's image load process doesn't throw a pyimage10 error\n",
        "            img = cv2.resize(img, (img_dims, img_dims))\n",
        "            img = np.dstack([img, img, img])\n",
        "            img = img.astype('float32') / 255\n",
        "            if cond=='/NORMAL/':\n",
        "                label = 0\n",
        "            elif cond=='/PNEUMONIA/':\n",
        "                label = 1\n",
        "            test_data.append(img)\n",
        "            test_labels.append(label)\n",
        "        \n",
        "    test_data = np.array(test_data)\n",
        "    test_labels = np.array(test_labels)\n",
        "    \n",
        "    return train_gen, test_gen, test_data, test_labels\n",
        "    \n",
        "\n",
        "###########\n",
        "#Util Component 4: Report file distributions\n",
        "#directoryProcessArray eg, = ['train', 'val', 'test'], in the case that training val and test folders exist in sub-dir for processing.\n",
        "def reportFileDistributions (___inputPath, directoryProcessArray):\n",
        "    for _set in directoryProcessArray:\n",
        "        n_normal = len(os.listdir(___inputPath + _set + '/NORMAL'))\n",
        "        n_infect = len(os.listdir(___inputPath + _set + '/PNEUMONIA'))\n",
        "        print('Set: {}, normal images: {}, regular pneumonia images: {}'.format(_set, n_normal, n_infect))"
      ],
      "metadata": {
        "id": "nATqQD5uX7Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting seeds for reproducibility\n",
        "seed = 232\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "jFVdw2srX7S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "img_dims = 150\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "qR-T94SCX7QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, output = defineModelArchitecture ( img_dims )"
      ],
      "metadata": {
        "id": "UwzhVpDWX7Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating model and compiling\n",
        "model_pneumoniaDetector = Model(inputs=inputs, outputs=output)\n",
        "model_pneumoniaDetector.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_pneumoniaDetector.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r_GF8c8X7Is",
        "outputId": "05c3c8bd-f041-4c49-fc7c-7f9f24d75da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 150, 150, 16)      448       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 150, 150, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 75, 75, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " separable_conv2d_16 (Separa  (None, 75, 75, 32)       688       \n",
            " bleConv2D)                                                      \n",
            "                                                                 \n",
            " separable_conv2d_17 (Separa  (None, 75, 75, 32)       1344      \n",
            " bleConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 75, 75, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 37, 37, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " separable_conv2d_18 (Separa  (None, 37, 37, 64)       2400      \n",
            " bleConv2D)                                                      \n",
            "                                                                 \n",
            " separable_conv2d_19 (Separa  (None, 37, 37, 64)       4736      \n",
            " bleConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 37, 37, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 18, 18, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " separable_conv2d_20 (Separa  (None, 18, 18, 128)      8896      \n",
            " bleConv2D)                                                      \n",
            "                                                                 \n",
            " separable_conv2d_21 (Separa  (None, 18, 18, 128)      17664     \n",
            " bleConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 18, 18, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 9, 9, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 9, 9, 128)         0         \n",
            "                                                                 \n",
            " separable_conv2d_22 (Separa  (None, 9, 9, 256)        34176     \n",
            " bleConv2D)                                                      \n",
            "                                                                 \n",
            " separable_conv2d_23 (Separa  (None, 9, 9, 256)        68096     \n",
            " bleConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 9, 9, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 4, 4, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,314,337\n",
            "Trainable params: 2,313,377\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_path_b = '/content/gdrive/MyDrive/DBSCAN.zip'"
      ],
      "metadata": {
        "id": "wJlBfHr1X6sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report file distributions\n",
        "reportFileDistributions (input_path_b, ['train', 'val', 'test'] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "8dgW8DLAY0tW",
        "outputId": "69a6555b-9b60-41ee-fcf7-f39e0a786e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-c8d248b41fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Report file distributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreportFileDistributions\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_path_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-1e3c824131cd>\u001b[0m in \u001b[0;36mreportFileDistributions\u001b[0;34m(___inputPath, directoryProcessArray)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreportFileDistributions\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m___inputPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectoryProcessArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirectoryProcessArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mn_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m___inputPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_set\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/NORMAL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mn_infect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m___inputPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_set\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/PNEUMONIA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Set: {}, normal images: {}, regular pneumonia images: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_infect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/DBSCAN.ziptrain/NORMAL'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the data\n",
        "train_gen, test_gen, test_data_b, test_labels_b = process_data(input_path_b, img_dims, batch_size)"
      ],
      "metadata": {
        "id": "sc3Ew4tcY0pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "renderConfusionMetrics(model_pneumoniaDetector, test_data_b, test_labels_b, True, train_gen, test_gen, batch_size, 60, 'model_weights.hdf5')"
      ],
      "metadata": {
        "id": "Cwjqyn4UY0l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, output = defineModelArchitecture(img_dims)\n",
        "\n",
        "# Creating model and compiling\n",
        "model_covid19PneumoniaDetector = Model(inputs=inputs, outputs=output)\n",
        "model_covid19PneumoniaDetector.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_covid19PneumoniaDetector.load_weights('model_weights.hdf5')"
      ],
      "metadata": {
        "id": "DdKtpKutY0iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_path_d = '/content/covid19_DCGAN'"
      ],
      "metadata": {
        "id": "ztt1NkI7Y0en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reportFileDistributions (input_path_d, ['train', 'test'])"
      ],
      "metadata": {
        "id": "1Xfi8QMgY0Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen_d, test_gen_d, test_data_d, test_labels_d = process_data(input_path_d, img_dims, batch_size)"
      ],
      "metadata": {
        "id": "uWQn0zyiY0NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "renderConfusionMetrics(model_covid19PneumoniaDetector, test_data_d, test_labels_d, True, train_gen_d, test_gen_d, batch_size, 10, 'covid19_model_weights.hdf5')"
      ],
      "metadata": {
        "id": "TXmlsBJQZJoo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}